{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f32776d3",
   "metadata": {},
   "source": [
    "# Proyecto 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efd46a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyspellchecker\n",
    "#!pip intall textatistic\n",
    "#!pip install -U LeXmo\n",
    "#!pip install emot\n",
    "#!pip install nrclex\n",
    "#!pip install swifter\n",
    "#!pip install spacy\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#!pip install enchant\n",
    "#!pip install language_tool_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79cfba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from tqdm import tqdm\n",
    "import swifter\n",
    "\n",
    "import string\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spellchecker import SpellChecker\n",
    "from textatistic import Textatistic\n",
    "from LeXmo import LeXmo\n",
    "import emot\n",
    "import nrclex\n",
    "from language_tool_python import LanguageTool\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "tqdm.pandas()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "spell = SpellChecker()\n",
    "tool = LanguageTool('en-US')\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "STOP_WORDS = stopwords.words('english')\n",
    "PUNCT_MARKS = list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09c68adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
       "1  On my perspective, I think that the face is a ...       Position   \n",
       "2  I think that the face is a natural landform be...          Claim   \n",
       "3  If life was on Mars, we would know by now. The...       Evidence   \n",
       "4  People thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness  \n",
       "0                Adequate  \n",
       "1                Adequate  \n",
       "2                Adequate  \n",
       "3                Adequate  \n",
       "4                Adequate  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')[:100]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d2268f",
   "metadata": {},
   "source": [
    "## Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2201112",
   "metadata": {},
   "source": [
    "### Fase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac91dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spelling_errors(text):\n",
    "    words = text.split()\n",
    "    misspelled = spell.unknown(words)\n",
    "    return len(misspelled)\n",
    "\n",
    "def grammar_errors(text):\n",
    "    matches = tool.check(text)\n",
    "    return len(matches)\n",
    "\n",
    "def punctuation_marks(text):\n",
    "    return sum([1 for char in text if char in PUNCT_MARKS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a23dd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10ecd5b7bb643288531b91f4e777660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7e39b42291491ba5c2e2cf401fb2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe081f15c744407819402e70292ab70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>spelling_errors</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>punctuation_marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
       "1  On my perspective, I think that the face is a ...       Position   \n",
       "2  I think that the face is a natural landform be...          Claim   \n",
       "3  If life was on Mars, we would know by now. The...       Evidence   \n",
       "4  People thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness  spelling_errors  grammar_errors  punctuation_marks  \n",
       "0                Adequate                7               2                  9  \n",
       "1                Adequate                4               2                  4  \n",
       "2                Adequate                2               1                  0  \n",
       "3                Adequate               11               3                 13  \n",
       "4                Adequate                2               1                  1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['spelling_errors'] = data['discourse_text'].swifter.apply(spelling_errors)\n",
    "data['grammar_errors'] = data['discourse_text'].swifter.apply(grammar_errors)\n",
    "data['punctuation_marks'] = data['discourse_text'].swifter.apply(punctuation_marks)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276bc1d7",
   "metadata": {},
   "source": [
    "### Fase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "668901a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"I'd\": \"I would\",\n",
    "    \"I'll\": \"I will\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "def handle_contractions(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [contractions[word] if word in contractions else word for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def spell_correction(text):\n",
    "    words = word_tokenize(text)\n",
    "    corrected_words = [spell.correction(word) if spell.correction(word) is not None else word for word in words]\n",
    "    return ' '.join(corrected_words)\n",
    "\n",
    "def end_sentence(text):\n",
    "    if text[-1] not in ['!', '?', '.']:\n",
    "        return text + '.'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f8f8f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d13bdbc9b0455cbd98af25c57a2633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320bcc68c59841a4b414eca195bf771a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc45070c82f4175a3a6b9fac31e03e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>spelling_errors</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>punctuation_marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>hi , i am isaac , i am going to be writing abo...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>on my perspective , i think that the face is a...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>i think that the face is a natural landlord be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>if life was on mars , we would know by now . t...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>people thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  hi , i am isaac , i am going to be writing abo...           Lead   \n",
       "1  on my perspective , i think that the face is a...       Position   \n",
       "2  i think that the face is a natural landlord be...          Claim   \n",
       "3  if life was on mars , we would know by now . t...       Evidence   \n",
       "4  people thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness  spelling_errors  grammar_errors  punctuation_marks  \n",
       "0                Adequate                7               2                  9  \n",
       "1                Adequate                4               2                  4  \n",
       "2                Adequate                2               1                  0  \n",
       "3                Adequate               11               3                 13  \n",
       "4                Adequate                2               1                  1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['discourse_text'] = data['discourse_text'].swifter.apply(handle_contractions)\n",
    "data['discourse_text'] = data['discourse_text'].swifter.apply(spell_correction)\n",
    "data['discourse_text'] = data['discourse_text'].swifter.apply(end_sentence)\n",
    "data['discourse_text'] = data['discourse_text'].str.lower()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79d6eb3",
   "metadata": {},
   "source": [
    "### Fase 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2202b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readability_features(text):\n",
    "    s = Textatistic(text)\n",
    "    return pd.Series([s.sent_count, s.word_count, s.sybl_count, s.char_count, s.polysyblword_count, s.dalechall_score,\n",
    "                      s.flesch_score, s.fleschkincaid_score, s.gunningfog_score, s.smog_score])\n",
    "\n",
    "def avg_word_length(text):\n",
    "    words = text.split()\n",
    "    word_lengths = [len(word) for word in words]\n",
    "    avg_word_length = sum(word_lengths)/len(words)\n",
    "    return(avg_word_length)\n",
    "\n",
    "def stop_words(text):\n",
    "    words = text.split()\n",
    "    return sum(1 for word in words if word.lower() in STOP_WORDS)\n",
    "\n",
    "def lexical_types(text):\n",
    "    words = word_tokenize(text)\n",
    "    lexical_types = set(words)\n",
    "    return len(lexical_types)\n",
    "\n",
    "def syntatic_complexity_features(text):\n",
    "    doc = nlp(text)\n",
    "    total_tokens = len(doc)\n",
    "    num_clauses = len([token for token in doc if token.dep_ == \"ROOT\"])\n",
    "    num_sub_clauses = len([token for token in doc if token.dep_ == \"acl\" or token.dep_ == \"advcl\"])\n",
    "    num_verb_phrases = len([chunk for chunk in doc.noun_chunks if chunk.root.pos_ == \"VERB\"])\n",
    "    num_complex_noun_phrases = len([chunk for chunk in doc.noun_chunks if len(chunk) > 1])\n",
    "\n",
    "    return pd.Series([num_clauses / total_tokens, num_sub_clauses / total_tokens, num_verb_phrases / total_tokens,\n",
    "                      num_complex_noun_phrases / total_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d956123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aabe513d9a64210a69ceb8e4a0bddcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b5155002504f2fb93062773d7be0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e36140c86c742be829e1e4d396e9e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4145ee2e85e34372a7d085dc7ef35b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc88b925ed9e469db462da72bc9152a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['text_length'] = data['discourse_text'].swifter.apply(len)\n",
    "data[['sent_count', 'word_count', 'sybl_count', 'char_count', \n",
    "      'polysyblword_count', 'dalechall_score', 'flesch_score',\n",
    "     'fleschkincaid_score', 'gunningfog_score', 'smog_score']] = data['discourse_text'].swifter.apply(readability_features)\n",
    "data['stop_words'] = data['discourse_text'].swifter.apply(stop_words)\n",
    "data['lexical_types'] = data['discourse_text'].swifter.apply(lexical_types)\n",
    "data[['clauses_prop', 'sub_clauses_prop', \n",
    "      'verb_phrases_prop', 'noun_phrases_prop']] = data['discourse_text'].swifter.apply(syntatic_complexity_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48cfb529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>spelling_errors</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>punctuation_marks</th>\n",
       "      <th>text_length</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>...</th>\n",
       "      <th>smog_score</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>lexical_types</th>\n",
       "      <th>clauses_prop</th>\n",
       "      <th>sub_clauses_prop</th>\n",
       "      <th>verb_phrases_prop</th>\n",
       "      <th>noun_phrases_prop</th>\n",
       "      <th>chars_per_word</th>\n",
       "      <th>words_per_sentence</th>\n",
       "      <th>sybl_per_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>hi , i am isaac , i am going to be writing abo...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>325</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.793538</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>on my perspective , i think that the face is a...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>214</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.125757</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>4.047619</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>26.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>i think that the face is a natural landlord be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.208143</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>4.047619</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>if life was on mars , we would know by now . t...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>374</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.516145</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>3.815789</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>24.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>people thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.129100</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  hi , i am isaac , i am going to be writing abo...           Lead   \n",
       "1  on my perspective , i think that the face is a...       Position   \n",
       "2  i think that the face is a natural landlord be...          Claim   \n",
       "3  if life was on mars , we would know by now . t...       Evidence   \n",
       "4  people thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness  spelling_errors  grammar_errors  punctuation_marks  \\\n",
       "0                Adequate                7               2                  9   \n",
       "1                Adequate                4               2                  4   \n",
       "2                Adequate                2               1                  0   \n",
       "3                Adequate               11               3                 13   \n",
       "4                Adequate                2               1                  1   \n",
       "\n",
       "   text_length  sent_count  ...  smog_score  stop_words  lexical_types  \\\n",
       "0          325         3.0  ...    7.793538          43             43   \n",
       "1          214         2.0  ...   10.125757          27             30   \n",
       "2          105         1.0  ...   11.208143          13             20   \n",
       "3          374         4.0  ...    9.516145          46             49   \n",
       "4          100         1.0  ...    3.129100          10             16   \n",
       "\n",
       "   clauses_prop  sub_clauses_prop  verb_phrases_prop  noun_phrases_prop  \\\n",
       "0      0.039474          0.000000                0.0           0.105263   \n",
       "1      0.042553          0.021277                0.0           0.127660   \n",
       "2      0.045455          0.045455                0.0           0.136364   \n",
       "3      0.047059          0.035294                0.0           0.058824   \n",
       "4      0.052632          0.052632                0.0           0.052632   \n",
       "\n",
       "   chars_per_word  words_per_sentence  sybl_per_sentence  \n",
       "0        3.571429           23.333333              27.00  \n",
       "1        4.047619           21.000000              26.50  \n",
       "2        4.047619           21.000000              27.00  \n",
       "3        3.815789           19.000000              24.75  \n",
       "4        4.555556           18.000000              20.00  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['chars_per_word'] = data['char_count'] / data['word_count']\n",
    "data['words_per_sentence'] = data['word_count'] / data['sent_count']\n",
    "data['sybl_per_sentence'] = data['sybl_count'] / data['sent_count'] \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7998d3c9",
   "metadata": {},
   "source": [
    "### Fase 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "836b3413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    removed_stop_words = ' '.join([word for word in text.split() if word not in STOP_WORDS])\n",
    "    return removed_stop_words\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in text.split()]\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "    return lemmatized_text\n",
    "\n",
    "def emotions(text):\n",
    "    emo = LeXmo.LeXmo(text)\n",
    "    return pd.Series([emo['anger'], emo['anticipation'], emo['disgust'], emo['fear'], emo['joy'], emo['negative'],\n",
    "                      emo['positive'], emo['sadness'], emo['surprise'], emo['trust']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['discourse_text'] = data['discourse_text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "data['discourse_text'] = data['discourse_text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "data['discourse_text'] = data['discourse_text'].swifter.apply(lemmatize_text)\n",
    "data[['anger', 'anticipation', 'disgust', \n",
    "      'fear', 'joy', 'negative', 'positive',\n",
    "     'sadness', 'surprise', 'trust'] = data['discourse_text'].swifter.apply(remove_stop_words).swifter.apply(emotions)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4643faa",
   "metadata": {},
   "source": [
    "### Exportacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22234b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['discourse_id', 'essay_id', 'discourse_text', 'discourse_type',\n",
       "       'discourse_effectiveness', 'spelling_errors', 'grammar_errors',\n",
       "       'punctuation_marks', 'text_length', 'sent_count', 'word_count',\n",
       "       'sybl_count', 'char_count', 'polysyblword_count', 'dalechall_score',\n",
       "       'flesch_score', 'fleschkincaid_score', 'gunningfog_score', 'smog_score',\n",
       "       'stop_words', 'lexical_types', 'clauses_prop', 'sub_clauses_prop',\n",
       "       'verb_phrases_prop', 'noun_phrases_prop', 'chars_per_word',\n",
       "       'words_per_sentence', 'sybl_per_sentence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a2c119e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>words_per_sentence</th>\n",
       "      <th>readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>hi isaac going writing face mars natural landf...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>67</td>\n",
       "      <td>3.731343</td>\n",
       "      <td>3</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>7.894030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>perspective think face natural landform dont t...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>41</td>\n",
       "      <td>4.121951</td>\n",
       "      <td>2</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>11.126829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>think face natural landform life mars descover...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>21</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>12.209524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>life mars would know reason think natural land...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>72</td>\n",
       "      <td>4.027778</td>\n",
       "      <td>4</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.537778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>people thought face formed alieans thought lif...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>18</td>\n",
       "      <td>4.611111</td>\n",
       "      <td>1</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  hi isaac going writing face mars natural landf...           Lead   \n",
       "1  perspective think face natural landform dont t...       Position   \n",
       "2  think face natural landform life mars descover...          Claim   \n",
       "3  life mars would know reason think natural land...       Evidence   \n",
       "4  people thought face formed alieans thought lif...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness  word_count  avg_word_length  sentences_count  \\\n",
       "0                Adequate          67         3.731343                3   \n",
       "1                Adequate          41         4.121951                2   \n",
       "2                Adequate          21         4.000000                1   \n",
       "3                Adequate          72         4.027778                4   \n",
       "4                Adequate          18         4.611111                1   \n",
       "\n",
       "   words_per_sentence  readability  \n",
       "0           22.333333     7.894030  \n",
       "1           20.500000    11.126829  \n",
       "2           21.000000    12.209524  \n",
       "3           18.000000     8.537778  \n",
       "4           18.000000     3.600000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_csv('train_features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
